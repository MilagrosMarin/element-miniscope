{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataJoint Elements for Miniscope Calcium Imaging\n",
    "\n",
    "#### Open source data pipeline for managing and analyzing functional calcium imaging data acquired with UCLA Miniscopes.\n",
    "\n",
    "Welcome to the tutorial for the DataJoint Element for Miniscope Calcium Imaging. This\n",
    "tutorial aims to provide a comprehensive understanding of the open-source data pipeline\n",
    "created using `element-miniscope`. \n",
    "\n",
    "The package is designed to seamlessly ingest and track scan-level metadata, image\n",
    "processing, and curation results across subjects and sessions. By the end of this tutorial you will have a clear grasp on setting up and integrating\n",
    "`element-miniscope` into your specific research projects and your lab.\n",
    "\n",
    "\n",
    "![flowchart](https://raw.githubusercontent.com/datajoint/element-miniscope/main/images/flowchart.svg)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1. This tutorial assumes you already understand different table types in\n",
    "   `datajoint-python`. \n",
    "2. This tutorial assumes you have a basic understanding of the functionality of the\n",
    "   `.populate()` method used in `datajoint-python` to automatically insert data into\n",
    "   `Imported` and `Computed` tables.  \n",
    "\n",
    "Please see the [datajoint tutorials GitHub\n",
    "repository](https://github.com/datajoint/datajoint-tutorials/tree/main) before proceeding.\n",
    "\n",
    "**Key Components and Objectives**\n",
    "\n",
    "+ **Setup**\n",
    "+ **Activate the DataJoint pipeline.**\n",
    "1. **Insert session-level metadata.**\n",
    "2. **Extract scan-level (recording-level) metadata.**\n",
    "3. **Perform image processing using\n",
    "   [`CaImAn`](https://github.com/flatironinstitute/CaImAn).**\n",
    "4. **Curate the results (optional).**\n",
    "5. **Visualize the results.**\n",
    "\n",
    "#### Setup\n",
    "\n",
    "This tutorial examines data from a UCLA miniscope recording acquired using the Miniscope\n",
    "DAQ V4. The goal is to extract fluorescence and deconvolved activity traces and use\n",
    "these traces to study neuronal calcium dynamics and neural activity during\n",
    "specific behaviors or tasks.\n",
    "\n",
    "The results of this element can be combined with **other modalities** to create a\n",
    "complete, customizable data pipeline for your specific lab or study. For instance, you\n",
    "can combine `element-miniscope` with `element-calcium-imaging` or `element-deeplabcut`\n",
    "to characterize neural activity along with markerless pose-estimation during behavior.\n",
    "\n",
    "Let's start this tutorial by importing the packages necessary to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the tutorial is run in Codespaces, there is a local database private to you for\n",
    "experimentation. Let's connect to the database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Activate the DataJoint Pipeline**\n",
    "\n",
    "This tutorial activates the `miniscope.py` module from `element-miniscope`, along with\n",
    "upstream depedencies from `element-animal` and `element-session`. Please refer to the\n",
    "[`tutorial_pipeline.py`](./tutorial_pipeline.py) for the source code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_pipeline import lab, subject, session, miniscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent the tables in the `miniscope` schema as well as some of the upstream\n",
    "dependencies to `session` and `subject` schemas as a diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dj.Diagram(subject.Subject) + dj.Diagram(session.Session) + dj.Diagram(miniscope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident from the diagram, this data pipeline encompasses tables associated with\n",
    "recording-level (scan-level) metadata, image processing results, and optional curation\n",
    "of image processing. A few tables such as `subject.Subject` or `session.Session` are\n",
    "inherited from `element-animal` and `element-session`, respectively, and while important\n",
    "for a complete pipeline, fall outside the scope of `element-miniscope` and will\n",
    "therefore, not be explored extensively here. The primary focus of this tutorial is on\n",
    "the `miniscope` schema.\n",
    "\n",
    "##### 1. **Insert session-level metadata.**\n",
    "\n",
    "Let's start with the first table in the schema diagram (i.e. `subject.Subject` table).\n",
    "\n",
    "To know what data to insert into the table, we can view its dependencies and attributes\n",
    "using the `.describe` and `.heading` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject.Subject.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.heading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells above show all attributes of the subject table.\n",
    "We will insert data into the\n",
    "`subject.Subject` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.insert1(\n",
    "    dict(subject=\"subject1\", subject_birth_date=\"2023-01-01\", sex=\"U\")\n",
    ")\n",
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the steps above for the `Session` table and see how the output varies between\n",
    "`.describe` and `.heading`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session.Session.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session.heading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `describe`, displays the table's structure and highlights its dependencies, such as its reliance on the `Subject` table. These dependencies represent foreign key references, linking data across tables.\n",
    "\n",
    "On the other hand, `heading` provides an exhaustive list of the table's attributes. This\n",
    "list includes both the attributes declared in this table and any inherited from upstream\n",
    "tables.\n",
    "\n",
    "With this understanding, let's move on to insert a session associated with our subject.\n",
    "\n",
    "We will insert into the `session.Session` table by passing a dictionary to the `insert1` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_key = dict(subject=\"subject1\", session_datetime=\"2023-01-01 00:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session.insert1(session_key)\n",
    "session.Session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. **Extract Scan-level Metadata.**\n",
    "\n",
    "Every experimental session produces a set of data files. The `SessionDirectory` table's\n",
    "purpose is to locate these files. It references a directory path relative to a root\n",
    "directory, defined in `dj.config[\"custom\"]`. More\n",
    "information about `dj.config` is provided in the [documentation](https://datajoint.com/docs/elements/user-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.SessionDirectory.insert1(dict(**session_key, session_dir=\"session1\"))\n",
    "session.SessionDirectory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the workflow diagram indicates, the first table in the `miniscope` schema is the `miniscope.Recording` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(miniscope.Recording.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.Recording.heading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the `describe()` method, this lab contains a dependency on the `Device` table within the `lab` schema. Let's quickly insert a miniscope device before inserting into `miniscope.Recording`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.Device.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.Device.insert1(dict(device=\"miniscope A\", modality=\"miniscope\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.Recording.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        recording_id=1,\n",
    "        device=\"miniscope A\",\n",
    "        acq_software=\"Miniscope-DAQ-V4\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the upcoming cells, we'll make use of the `populate()` method to fill the `miniscope.RecordingInfo` table and its part table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.RecordingInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.RecordingInfo.File()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.RecordingInfo.populate(session_key, display_progress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the information was entered into each of these tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.RecordingInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.RecordingInfo.File()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. **Perform Image Processing using CaImAn.**\n",
    "\n",
    "We're almost ready to perform image processing with `CaImAn`. An important step before\n",
    "processing is managing the parameters which will be used in that step. To do so, we will\n",
    "define the `CaImAn` parameters in a dictionary and insert them into a DataJoint table\n",
    "`ProcessingParamSet`. This table keeps track of all combinations of your image\n",
    "processing parameters. You can choose which parameters are used during processing in a\n",
    "later step.\n",
    "\n",
    "Let's view the attributes and insert data into `miniscope.ProcessingParamSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.ProcessingParamSet.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    decay_time=0.4,\n",
    "    pw_rigid=False,\n",
    "    max_shifts=(5, 5),\n",
    "    gSig_filt=(3, 3),\n",
    "    strides=(48, 48),\n",
    "    overlaps=(24, 24),\n",
    "    max_deviation_rigid=3,\n",
    "    border_nan=\"copy\",\n",
    "    method_init=\"corr_pnr\",\n",
    "    K=None,\n",
    "    gSig=(3, 3),\n",
    "    gSiz=(13, 13),\n",
    "    merge_thr=0.7,\n",
    "    p=1,\n",
    "    tsub=2,\n",
    "    ssub=1,\n",
    "    rf=40,\n",
    "    stride=20,\n",
    "    only_init=True,\n",
    "    nb=0,\n",
    "    nb_patch=0,\n",
    "    method_deconvolution=\"oasis\",\n",
    "    low_rank_background=None,\n",
    "    update_background_components=True,\n",
    "    min_corr=0.8,\n",
    "    min_pnr=10,\n",
    "    normalize_init=False,\n",
    "    center_psf=True,\n",
    "    ssub_B=2,\n",
    "    ring_size_factor=1.4,\n",
    "    del_duplicates=True,\n",
    "    border_pix=0,\n",
    "    min_SNR=3,\n",
    "    rval_thr=0.85,\n",
    "    use_cnn=False,\n",
    ")\n",
    "\n",
    "\n",
    "miniscope.ProcessingParamSet.insert_new_params(\n",
    "    processing_method=\"caiman\",\n",
    "    paramset_id=0,\n",
    "    paramset_desc=\"Miniscope analysis with CaImAn using default parameters\",\n",
    "    params=params,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've inserted kilosort parameters into the `ProcessingParamSet` table,\n",
    "we're almost ready to run image processing. DataJoint uses a `ProcessingTask` table to\n",
    "manage which `Recording` and `ProcessingParamSet` should be used during processing. \n",
    "\n",
    "This table is important for defining several important aspects of\n",
    "downstream processing. Let's view the attributes to get a better understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.ProcessingTask.heading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ProcessingTask` table contains two important attributes: \n",
    "+ `paramset_id` \n",
    "+ `task_mode` \n",
    "\n",
    "The `paramset_id` attribute tracks\n",
    "your `CaImAn` parameter sets. You can choose the parameter set that should be used for\n",
    "image processing. For example, `paramset_id=0` may contain\n",
    "default parameters for `CaImAn` processing whereas `paramset_id=1` contains your custom\n",
    "parameters for motion correction. This\n",
    "attribute tells the `Processing` table which set of parameters you are processing in a given `populate()`.\n",
    "\n",
    "The `task_mode` attribute can be set to either `load` or `trigger`. When set to `load`,\n",
    "running the processing step initiates a search for existing `CaImAn` output files. When set to `trigger`, the\n",
    "processing step will run `CaImAn` on the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.ProcessingTask.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        recording_id=1,\n",
    "        paramset_id=0,\n",
    "        task_mode=\"load\",  # load or trigger\n",
    "        processing_output_dir=\"session1\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.Processing.populate(session_key, display_progress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While image processing is completed in the above step, you can optionally curate\n",
    "the output of image processing using the `Curation` table. For this demo, we\n",
    "will simply use the results ingested from the `Processing` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.Curation.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_key = (miniscope.ProcessingTask & session_key).fetch1(\"KEY\")\n",
    "miniscope.Curation().create1_from_clustering_task(clustering_key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Curation` table receives an entry, we can populate the remaining\n",
    "tables in the workflow including `Segmentation`, `Fluorescence`, and `Activity`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniscope.MotionCorrection.populate(session_key, display_progress=True)\n",
    "miniscope.Segmentation.populate(session_key, display_progress=True)\n",
    "miniscope.Fluorescence.populate(session_key, display_progress=True)\n",
    "miniscope.Activity.populate(session_key, display_progress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've populated the tables in this workflow, there are one of\n",
    "several next steps. If you have an existing workflow for\n",
    "aligning waveforms to behavior data or other stimuli, you can easily\n",
    "invoke `element-event` or define your custom DataJoint tables to extend the\n",
    "pipeline.\n",
    "\n",
    "##### 5. **Visualize the results.**\n",
    "\n",
    "In this tutorial, we will do some exploratory analysis by fetching the data from the database and creating a few plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = (imaging.Fluorescence.Trace & \"mask = '10'\").fetch1(\"fluorescence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the query above, we fetch a single fluorescence trace from the `fluorescence`\n",
    "attribute in the `Trace` part table belonging to the `Fluorescence` table.\n",
    "We also restrict the query to mask number 10.\n",
    "\n",
    "Let's go ahead and fetch the sampling rate and plot the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = (scan.ScanInfo & session_key & \"scan_id=0\").fetch1(\"fps\")\n",
    "\n",
    "plt.plot(np.r_[: trace.size] * 1 / sampling_rate, trace)\n",
    "plt.title(\"Fluorescence trace for mask 10\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Activity (a.u.)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataJoint queries are a highly flexible tool to manipulate and visualize your data.\n",
    "After all, visualizing traces or generating rasters is likely just the start of\n",
    "your analysis workflow. This can also make the queries seem more complex at\n",
    "first. However, we'll walk through them slowly to simplify their content in this notebook. \n",
    "\n",
    "The examples below perform several operations using DataJoint queries:\n",
    "- Use **multiple restrictions** to fetch the average image generated during motion correction.\n",
    "- Use a **join** operation and **multiple restrictions** to fetch x and y coordinates of\n",
    "  masks generated during image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_image = (imaging.MotionCorrection.Summary & session_key & \"field_idx=0\").fetch1(\n",
    "    \"average_image\"\n",
    ")\n",
    "\n",
    "mask_xpix, mask_ypix = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & session_key\n",
    "    & \"mask_center_z=0\"\n",
    "    & \"mask_npix > 130\"\n",
    ").fetch(\"mask_xpix\", \"mask_ypix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask coordinates can be overlayed with the average image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image = np.zeros(np.shape(average_image), dtype=bool)\n",
    "for xpix, ypix in zip(mask_xpix, mask_ypix):\n",
    "    mask_image[ypix, xpix] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(average_image)\n",
    "plt.contour(mask_image, colors=\"white\", linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Following this tutorial, we have:\n",
    "\n",
    "+ Covered the essential functionality of `element-miniscope`.\n",
    "+ Learned how to manually insert data into tables.\n",
    "+ Execute image processing with `CaImAn`.\n",
    "+ Visualize the results.\n",
    "\n",
    "##### Run this tutorial on your own data.\n",
    "\n",
    "To run this tutorial notebook on your own data, please use the following steps:\n",
    "- Download the [mysql-docker image for\n",
    "  DataJoint](https://github.com/datajoint/mysql-docker) and run the container according\n",
    "  to the instructions provide in the repository.\n",
    "- Create a fork of this repository to your GitHub account.\n",
    "- Clone the repository and open the files using your IDE.\n",
    "- Add a code cell immediately after the first code cell in the notebook - we will setup\n",
    "  the local connection using this cell. In this cell, type in the following code. \n",
    "\n",
    "```python\n",
    "import datajoint as dj\n",
    "dj.config[\"database.host\"] = \"localhost\"\n",
    "dj.config[\"database.user\"] = \"<your-username>\"\n",
    "dj.config[\"database.password\"] = \"<your-password>\"\n",
    "dj.config[\"custom\"] = {\"imaging_root_data_dir\": \"path/to/your/data/dir\",\n",
    "\"database_prefix\": \"<your-username_>\"}\n",
    "dj.config.save_local()\n",
    "dj.conn()\n",
    "```\n",
    "\n",
    "- Run this code block above and proceed with the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff52d424e56dd643d8b2ec122f40a2e279e94970100b4e6430cb9025a65ba4cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
